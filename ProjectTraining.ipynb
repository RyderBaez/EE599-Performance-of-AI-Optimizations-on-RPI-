{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxscript\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSB4WrJNOC5H",
        "outputId": "50c8f054-07b8-45ed-f925-da1ae3468756"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.12-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting onnx>=1.16 (from onnxscript)\n",
            "  Downloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.5.6-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.0/683.0 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.12-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, onnx_ir, onnxscript\n",
            "Successfully installed onnx-1.20.0 onnx_ir-0.1.12 onnxscript-0.5.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3KW5uPZtcXjQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "# Device and save directory\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SAVE_DIR = \"rpi_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform and load CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "16NC9EO5cehZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            out = model(x)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def export_to_onnx(model, name, input_shape=(1,3,224,224)):\n",
        "    model.eval()\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    dummy_input = torch.randn(*input_shape)\n",
        "    onnx_path = os.path.join(SAVE_DIR, name + \".onnx\")\n",
        "    torch.onnx.export(\n",
        "        model.to(\"cpu\"),\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=12,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['input'],\n",
        "        output_names=['output'],\n",
        "        dynamic_axes={'input': {0:'batch_size'}, 'output': {0:'batch_size'}}\n",
        "    )\n",
        "    print(f\"[ONNX] Saved: {onnx_path}\")\n"
      ],
      "metadata": {
        "id": "hoP7d2Fsce0e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=EPOCHS):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        acc = evaluate(model)\n",
        "        print(f\"Epoch {epoch+1}: loss={running_loss/len(train_loader):.4f}, test_acc={acc:.4f}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "B69BKuaDce99"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning\n",
        "def prune_model(model, amount=0.3):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            prune.l1_unstructured(m, \"weight\", amount=amount)\n",
        "            prune.remove(m, \"weight\")\n",
        "    return model\n",
        "\n",
        "# Dynamic Quantization\n",
        "def quantize_model(model):\n",
        "    return torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Distillation\n",
        "def train_distilled(student, teacher, epochs=EPOCHS):\n",
        "    teacher.eval()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=1e-3)\n",
        "    alpha, T = 0.5, 4.0\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            s_out = student(x)\n",
        "            with torch.no_grad():\n",
        "                t_out = teacher(x)\n",
        "            loss = alpha*F.cross_entropy(s_out, y) + (1-alpha)*F.kl_div(\n",
        "                F.log_softmax(s_out/T, dim=1),\n",
        "                F.softmax(t_out/T, dim=1),\n",
        "                reduction=\"batchmean\"\n",
        "            )*(T*T)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = evaluate(student)\n",
        "        print(f\"[Distilled] Epoch {epoch+1}: test_acc={acc:.4f}\")\n",
        "    return student\n"
      ],
      "metadata": {
        "id": "5JRQAGv-cfHt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first cell of training model\n",
        "model = models.mobilenet_v2(weights=\"MobileNet_V2_Weights.IMAGENET1K_V1\")\n",
        "model.classifier[1] = nn.Linear(1280, 10)\n",
        "baseline = train_model(model)\n",
        "torch.save(baseline.state_dict(), os.path.join(SAVE_DIR, \"baseline_fp32.pt\"))\n",
        "export_to_onnx(baseline, \"baseline_fp32\")  # mandatory for RPi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW2hOznPcfQ-",
        "outputId": "6ccbe1dc-e789-4bdf-9b17-55f48346cae5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss=0.5268, test_acc=0.8495\n",
            "Epoch 2: loss=0.3345, test_acc=0.8861\n",
            "Epoch 3: loss=0.2750, test_acc=0.9017\n",
            "Epoch 4: loss=0.2324, test_acc=0.9000\n",
            "Epoch 5: loss=0.2008, test_acc=0.9058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3323149129.py:18: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1208 00:13:05.079000 994 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 104 of general pattern rewrite rules.\n",
            "[ONNX] Saved: rpi_models/baseline_fp32.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Quant should happen on RPI doesn't work otherwise\n",
        "quant = quantize_model(baseline)\n",
        "torch.save(quant.state_dict(), os.path.join(SAVE_DIR, \"quantized_int8.pt\"))\n",
        "export_to_onnx(quant, \"quantized_int8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "hHc6k-UpcgAE",
        "outputId": "fdf1924d-2222-41f8-eb1e-1323c90d1c31"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2252291475.py:11: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  return torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
            "/tmp/ipython-input-3323149129.py:18: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1208 00:17:55.040000 994 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ❌\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=True)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=True)`... ❌\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TorchExportError",
          "evalue": "Failed to export the model with torch.export. \u001b[96mThis is step 1/3\u001b[0m of exporting the model to ONNX. Next steps:\n- Modify the model code for `torch.export.export` to succeed. Refer to https://pytorch.org/docs/stable/generated/exportdb/index.html for more information.\n- Debug `torch.export.export` and submit a PR to PyTorch.\n- Create an issue in the PyTorch GitHub repository against the \u001b[96m*torch.export*\u001b[0m component and attach the full error stack as well as reproduction scripts.\n\n## Exception summary\n\n<class 'AttributeError'>: __torch__.torch.classes.quantized.LinearPackedParamsBase (of Python compilation unit at: 0) does not have a field with name '__obj_flatten__'\n\n(Refer to the full stack trace above for more information.)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_capture_strategies.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, args, kwargs, dynamic_shapes)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mexported_program\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_capture_strategies.py\u001b[0m in \u001b[0;36m_capture\u001b[0;34m(self, model, args, kwargs, dynamic_shapes)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 return torch.export.export(\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, prefer_deferred_runtime_asserts_over_guards)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_msg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, prefer_deferred_runtime_asserts_over_guards)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         return _export(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, prefer_deferred_runtime_asserts_over_guards)\u001b[0m\n\u001b[1;32m   2254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexport_training_ir_rollout_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m         ep = _export_for_training(\n\u001b[0m\u001b[1;32m   2256\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/exported_program.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0munset_fake_temporarily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_export_for_training\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, prefer_deferred_runtime_asserts_over_guards)\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2071\u001b[0;31m     export_artifact = export_func(\n\u001b[0m\u001b[1;32m   2072\u001b[0m         \u001b[0mmod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/export/_trace.py\u001b[0m in \u001b[0;36m_non_strict_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, orig_in_spec, prefer_deferred_runtime_asserts_over_guards, _to_aten_func)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         with (\n\u001b[0;32m-> 1992\u001b[0;31m             _fakify_script_objects(mod, fake_args, fake_kwargs, fake_mode) as (\n\u001b[0m\u001b[1;32m   1993\u001b[0m                 \u001b[0mpatched_mod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_export/non_strict_utils.py\u001b[0m in \u001b[0;36m_fakify_script_objects\u001b[0;34m(mod, args, kwargs, fake_mode)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_class_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_script_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0mfake_script_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_fakify_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfqn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfqns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_export/non_strict_utils.py\u001b[0m in \u001b[0;36m_maybe_fakify_obj\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_fakify_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mfake_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_class_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_to_fake_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0mfake_to_real\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfake_obj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/fake_class_registry.py\u001b[0m in \u001b[0;36mmaybe_to_fake_obj\u001b[0;34m(fake_mode, x)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_disable_current_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mflat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__obj_flatten__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: __torch__.torch.classes.quantized.LinearPackedParamsBase (of Python compilation unit at: 0) does not have a field with name '__obj_flatten__'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTorchExportError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-381177640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantized_int8.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexport_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quantized_int8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3323149129.py\u001b[0m in \u001b[0;36mexport_to_onnx\u001b[0;34m(model, name, input_shape)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0monnx_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     torch.onnx.export(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    294\u001b[0m         }\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         return _compat.export_compat(\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_compat.py\u001b[0m in \u001b[0;36mexport_compat\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, legacy_export_kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_complex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         onnx_program = _core.export(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_is_onnx_exporting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Ensure it resets even if an exception occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_core.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, kwargs, registry, dynamic_shapes, input_names, output_names, report, verify, profile, dump_exported_program, artifacts_dir, verbose)\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0;31m# torch.jit.trace is due to the fallback and can be confusing to users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0;31m# We save all errors in the error report.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m             raise _errors.TorchExportError(\n\u001b[0m\u001b[1;32m   1386\u001b[0m                 \u001b[0m_STEP_ONE_ERROR_MESSAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 + (\n",
            "\u001b[0;31mTorchExportError\u001b[0m: Failed to export the model with torch.export. \u001b[96mThis is step 1/3\u001b[0m of exporting the model to ONNX. Next steps:\n- Modify the model code for `torch.export.export` to succeed. Refer to https://pytorch.org/docs/stable/generated/exportdb/index.html for more information.\n- Debug `torch.export.export` and submit a PR to PyTorch.\n- Create an issue in the PyTorch GitHub repository against the \u001b[96m*torch.export*\u001b[0m component and attach the full error stack as well as reproduction scripts.\n\n## Exception summary\n\n<class 'AttributeError'>: __torch__.torch.classes.quantized.LinearPackedParamsBase (of Python compilation unit at: 0) does not have a field with name '__obj_flatten__'\n\n(Refer to the full stack trace above for more information.)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned = prune_model(model)\n",
        "pruned = train_model(pruned)\n",
        "torch.save(pruned.state_dict(), os.path.join(SAVE_DIR, \"pruned_30.pt\"))\n",
        "export_to_onnx(pruned, \"pruned_30\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ZtH34WcgGr",
        "outputId": "25784a27-2e7a-43b9-b3a4-f9cbbd69c774"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: loss=0.2060, test_acc=0.9040\n",
            "Epoch 2: loss=0.1722, test_acc=0.9007\n",
            "Epoch 3: loss=0.1524, test_acc=0.9083\n",
            "Epoch 4: loss=0.1395, test_acc=0.9083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3323149129.py:18: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1208 00:43:30.189000 994 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: loss=0.1252, test_acc=0.9105\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 104 of general pattern rewrite rules.\n",
            "[ONNX] Saved: rpi_models/pruned_30.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student = model\n",
        "baseline = baseline.to(DEVICE)\n",
        "distilled = train_distilled(student, baseline)\n",
        "torch.save(distilled.state_dict(), os.path.join(SAVE_DIR, \"distilled.pt\"))\n",
        "export_to_onnx(distilled, \"distilled\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAZgTvscgOk",
        "outputId": "441dcf92-1485-4ca0-f381-3fcb343f5d2b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Distilled] Epoch 1: test_acc=0.9104\n",
            "[Distilled] Epoch 2: test_acc=0.9168\n",
            "[Distilled] Epoch 3: test_acc=0.9223\n",
            "[Distilled] Epoch 4: test_acc=0.9211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3323149129.py:18: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1208 01:08:00.423000 994 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Distilled] Epoch 5: test_acc=0.9155\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 104 of general pattern rewrite rules.\n",
            "[ONNX] Saved: rpi_models/distilled.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#entering models that have more than one feature\n",
        "# Start from a trained baseline\n",
        "hybrid_model = prune_model(model)\n",
        "hybrid_model = train_model(hybrid_model)  # optional fine-tuning after pruning\n",
        "hybrid_model = quantize_model(hybrid_model)\n",
        "\n",
        "# Save and export\n",
        "torch.save(hybrid_model.state_dict(), os.path.join(SAVE_DIR, \"pruned_quantized.pt\"))\n",
        "export_to_onnx(hybrid_model, \"pruned_quantized\")\n"
      ],
      "metadata": {
        "id": "6PGapn_FcgXj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = model\n",
        "baseline = baseline.to(DEVICE)\n",
        "student = train_distilled(student, baseline)  # distillation\n",
        "student = quantize_model(student)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"distilled_quantized.pt\"))\n",
        "export_to_onnx(student, \"distilled_quantized\")\n"
      ],
      "metadata": {
        "id": "dpKFvINvcgeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = prune_model(model)\n",
        "baseline = baseline.to(DEVICE)\n",
        "student = train_distilled(student, baseline)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"pruned_distilled.pt\"))\n",
        "export_to_onnx(student, \"pruned_distilled\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjjrT2zfdO9k",
        "outputId": "b55baac4-8afa-4b82-af8e-355f8e55c023"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Distilled] Epoch 1: test_acc=0.9087\n",
            "[Distilled] Epoch 2: test_acc=0.9202\n",
            "[Distilled] Epoch 3: test_acc=0.9161\n",
            "[Distilled] Epoch 4: test_acc=0.9177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3323149129.py:18: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1208 01:32:14.393000 994 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 12 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Distilled] Epoch 5: test_acc=0.9106\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 12).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 12 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 104 of general pattern rewrite rules.\n",
            "[ONNX] Saved: rpi_models/pruned_distilled.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student = prune_model(model)\n",
        "baseline = baseline.to(DEVICE)\n",
        "student = train_distilled(student, baseline)\n",
        "student = quantize_model(student)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"pruned_distilled_quantized.pt\"))\n",
        "export_to_onnx(student, \"pruned_distilled_quantized\")\n"
      ],
      "metadata": {
        "id": "d_nuDwaHdO_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}