{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KW5uPZtcXjQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "# Device and save directory\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "SAVE_DIR = \"rpi_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform and load CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "16NC9EO5cehZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            out = model(x)\n",
        "            pred = out.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def export_to_onnx(model, name, input_shape=(1,3,224,224)):\n",
        "    model.eval()\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    dummy_input = torch.randn(*input_shape)\n",
        "    onnx_path = os.path.join(SAVE_DIR, name + \".onnx\")\n",
        "    torch.onnx.export(\n",
        "        model.to(\"cpu\"),\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=12,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['input'],\n",
        "        output_names=['output'],\n",
        "        dynamic_axes={'input': {0:'batch_size'}, 'output': {0:'batch_size'}}\n",
        "    )\n",
        "    print(f\"[ONNX] Saved: {onnx_path}\")\n"
      ],
      "metadata": {
        "id": "hoP7d2Fsce0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, epochs=EPOCHS):\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        acc = evaluate(model)\n",
        "        print(f\"Epoch {epoch+1}: loss={running_loss/len(train_loader):.4f}, test_acc={acc:.4f}\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "B69BKuaDce99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pruning\n",
        "def prune_model(model, amount=0.3):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            prune.l1_unstructured(m, \"weight\", amount=amount)\n",
        "            prune.remove(m, \"weight\")\n",
        "    return model\n",
        "\n",
        "# Dynamic Quantization\n",
        "def quantize_model(model):\n",
        "    return torch.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Distillation\n",
        "def train_distilled(student, teacher, epochs=EPOCHS):\n",
        "    teacher.eval()\n",
        "    optimizer = optim.Adam(student.parameters(), lr=1e-3)\n",
        "    alpha, T = 0.5, 4.0\n",
        "    for epoch in range(epochs):\n",
        "        student.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            s_out = student(x)\n",
        "            with torch.no_grad():\n",
        "                t_out = teacher(x)\n",
        "            loss = alpha*F.cross_entropy(s_out, y) + (1-alpha)*F.kl_div(\n",
        "                F.log_softmax(s_out/T, dim=1),\n",
        "                F.softmax(t_out/T, dim=1),\n",
        "                reduction=\"batchmean\"\n",
        "            )*(T*T)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = evaluate(student)\n",
        "        print(f\"[Distilled] Epoch {epoch+1}: test_acc={acc:.4f}\")\n",
        "    return student\n"
      ],
      "metadata": {
        "id": "5JRQAGv-cfHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first cell of training model\n",
        "baseline = train_model(models.mobilenet_v2(num_classes=10))\n",
        "torch.save(baseline.state_dict(), os.path.join(SAVE_DIR, \"baseline_fp32.pt\"))\n",
        "export_to_onnx(baseline, \"baseline_fp32\")  # mandatory for RPi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "NW2hOznPcfQ-",
        "outputId": "0687f481-2f9d-4683-b530-8736469dd098"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1185747177.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_fp32.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexport_to_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_fp32\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mandatory for RPi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant = quantize_model(baseline)\n",
        "torch.save(quant.state_dict(), os.path.join(SAVE_DIR, \"quantized_int8.pt\"))\n",
        "export_to_onnx(quant, \"quantized_int8\")\n"
      ],
      "metadata": {
        "id": "hHc6k-UpcgAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned = prune_model(models.mobilenet_v2(num_classes=10))\n",
        "pruned = train_model(pruned)\n",
        "torch.save(pruned.state_dict(), os.path.join(SAVE_DIR, \"pruned_30.pt\"))\n",
        "export_to_onnx(pruned, \"pruned_30\")\n"
      ],
      "metadata": {
        "id": "n6ZtH34WcgGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = models.mobilenet_v2(num_classes=10)\n",
        "distilled = train_distilled(student, baseline)\n",
        "torch.save(distilled.state_dict(), os.path.join(SAVE_DIR, \"distilled.pt\"))\n",
        "export_to_onnx(distilled, \"distilled\")\n"
      ],
      "metadata": {
        "id": "jLAZgTvscgOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#entering models that have more than one feature\n",
        "# Start from a trained baseline\n",
        "hybrid_model = prune_model(models.mobilenet_v2(num_classes=10))\n",
        "hybrid_model = train_model(hybrid_model)  # optional fine-tuning after pruning\n",
        "hybrid_model = quantize_model(hybrid_model)\n",
        "\n",
        "# Save and export\n",
        "torch.save(hybrid_model.state_dict(), os.path.join(SAVE_DIR, \"pruned_quantized.pt\"))\n",
        "export_to_onnx(hybrid_model, \"pruned_quantized\")\n"
      ],
      "metadata": {
        "id": "6PGapn_FcgXj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = models.mobilenet_v2(num_classes=10)\n",
        "student = train_distilled(student, baseline)  # distillation\n",
        "student = quantize_model(student)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"distilled_quantized.pt\"))\n",
        "export_to_onnx(student, \"distilled_quantized\")\n"
      ],
      "metadata": {
        "id": "dpKFvINvcgeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = prune_model(models.mobilenet_v2(num_classes=10))\n",
        "student = train_distilled(student, baseline)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"pruned_distilled.pt\"))\n",
        "export_to_onnx(student, \"pruned_distilled\")\n"
      ],
      "metadata": {
        "id": "SjjrT2zfdO9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student = prune_model(models.mobilenet_v2(num_classes=10))\n",
        "student = train_distilled(student, baseline)\n",
        "student = quantize_model(student)\n",
        "\n",
        "torch.save(student.state_dict(), os.path.join(SAVE_DIR, \"pruned_distilled_quantized.pt\"))\n",
        "export_to_onnx(student, \"pruned_distilled_quantized\")\n"
      ],
      "metadata": {
        "id": "d_nuDwaHdO_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}